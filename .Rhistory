ls()
install.packages("FNN")
# Generate Train Data
set.seed(1)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
ab = 1
eval_n <- 100
# Generate Train Data
set.seed(1)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
ab = 1
k = 1
ii = 1
# Generate Train Data
set.seed(ii)
eval_n = 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
# Generate Test Data
x_test <- sort(rnorm(eval_n))
# Generate Test Data
x_test <- sort(rnorm(eval_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_n)
k = 10
k = 10
# k = 10
eval_point <- x_test
idx_mat <- knnx_index(x_train, eval_point, k)
idx_mat
library(FNN)
idx_mat <- knnx.index(x_train, eval_point, k)
idx_mat
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx.mat[i,]])
}
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx.mat[i,]])
}
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
yhat
mean((yhat - y_test)^2)
yhat
eval_point
eval_point <- x_test
eval_point
yhat
y_test
mean((yhat - y_test)^2)
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
# Generate Test Data
x_test <- sort(rnorm(eval_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn.sig[k] <- mean((yhat - y_test)^2)
}
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
# Generate Test Data
x_test <- sort(rnorm(eval_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
eval_test_n = 10000
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
eval_test_n = 10000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
eval_test_n = 100
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
library(FNN)
ii = 1
eval_n <- 1000
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
eval_test_n = 1000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
plot(knn_sig, type = 'b', color = 'lightblue')
knn_sig <- seq(1,100,by = 5)
knn_sig <- seq(1,100,by = 5)
library(FNN)
ii = 1
eval_n <- 1000
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- seq(1,100,by = 5)
eval_test_n = 1000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig, type = 'b', color = 'lightblue')
plot(knn_sig, type = 'b', col = 'lightblue')
knn_sig
seq(1,100, by = 5)
kvec <- seq(1,100, by = 5)
library(FNN)
ii = 1
eval_n <- 500
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
kvec <- seq(1,100, by = 5)
error <- rep(0, length(kvec))
eval_test_n = 1000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig, type = 'b', col = 'lightblue')
plot(knn_sig, type = 'b', col = 'darkblue')
rm(list = ls())
gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
#setwd("C:/Users/uos_stat/Documents/GitHub/RankConsistency")
library(igraph)
library(MASS)
source('car_lib.R')
source('lib_rank.R')
source('sim.R')
source('real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
max_k = 15
cvec_r <- seq(0, max_k, by = 5)
file_idx = 1
inner_iter = 500
tau_result_matrix <- matrix(0, inner_iter, length(cvec_r)+1)
seed_v = 1
result_list = list()
result_list$naive = vector(mode = 'list', length = inner_iter)
result_list$gbt = vector(mode = 'list', length = inner_iter)
inner_iter = 1
cat("iteration::", seed_v, '\n')
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sc_list = vector(mode ='list', length = max_k)
## 논문에 나온대로 7:3으로 뽑음.
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.8)))
# cross validation : 여기서 sample 다시 생성해야 함!
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
######## naive BT fit
naive_est <- naive_btFunc(x,y, Qpmat, Gmat_hat)
result_list$naive[[seed_v]] <-  naive_est
######## gBT fit
cvec <- cvec_r/n*2 ## cvec : threshold c vector
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
race_mat_test<- as.matrix(rdata[-sample_idx,18:33])
num_vec_test <- rdata$V1[-sample_idx]
######## evaluate performances of standard BT estimator ####
tau_result_matrix[seed_v, 1] <- naive_eval(race_mat_test,num_vec_test,
naive_est)
######## evaluate performances of the two estimator ####
gbt_fit <- gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
gbt_fit
gbt_fit
rank_vec <- gbt_fit$gbt_est_mat
rank_vec <- gbt_fit$gbt_est_mat[1,]
rank_vec
rank(rank_vec, decreasing = T)
?rank
length(rank_vec) + 1 - rank(rank_vec)
naive_fit
# average rank
result_list$naive[[1]]
# average rank
#rank_vec<-result_list$naive[[1]]
rank_vec <- gbt_fit$gbt_est_mat[1,]
gbt_eval <- function(sc_list,race_mat_test, num_vec_test, cvec,
return_list = FALSE)
{
tau_result_vec <- rep(0, length(cvec))
perform_list = vector(mode = 'list', length = length(cvec))
gbt_est_mat <- matrix(NA, length(cvec), 43)
for (k in 1:length(cvec))
{
tmp<-sc_list[[k]]
tmp <-tmp[tmp[,1]!=0, 1:3]
p_set <-unique(c(tmp[,1:2]))
if (length(p_set) != 43)
{
tau_result_vec[k] <- NA
next
}
x <- matrix(0, nrow(tmp)*2, 43)
y <- rep(0, nrow(tmp)*2)
for ( i in 1:nrow(tmp))
{
vec1<-tmp[i,1:2]; vec2<- tmp[i,3]
x[2*(i-1)+1, vec1] <- c(1,-1) ; y[2*(i-1)+1] <- vec2
x[2*i, vec1] <- c(-1,1) ; y[2*i] <- abs(vec2 - 1)
}
x<- x[,-43]
fit<-glmnet(x,y, family = 'binomial', lambda = 0.000001)
gbt_est <- c(fit$beta[,1],0)
gbt_est_mat[k,] <- gbt_est
gbt_rankest <- 44 - rank(gbt_est)
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( gbt_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
if (return_list) perform_list[[k]] <-perform_v
tau_result_vec[k] <- mean(perform_v)
}
if(!return_list) perform_list = NULL
return(list(tau_result_vec = tau_result_vec, gbt_est_mat = gbt_est_mat))
}
######## evaluate performances of the two estimator ####
gbt_fit <- gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
######## evaluate performances of the two estimator ####
gbt_fit <- gbt_eval(sc_list, race_mat_test, num_vec_test, cvec,
return_list = TRUE)
gbt_fit
gbt_eval <- function(sc_list,race_mat_test, num_vec_test, cvec,
return_list = FALSE)
{
tau_result_vec <- rep(0, length(cvec))
perform_list = vector(mode = 'list', length = length(cvec))
gbt_est_mat <- matrix(NA, length(cvec), 43)
for (k in 1:length(cvec))
{
tmp<-sc_list[[k]]
tmp <-tmp[tmp[,1]!=0, 1:3]
p_set <-unique(c(tmp[,1:2]))
if (length(p_set) != 43)
{
tau_result_vec[k] <- NA
next
}
x <- matrix(0, nrow(tmp)*2, 43)
y <- rep(0, nrow(tmp)*2)
for ( i in 1:nrow(tmp))
{
vec1<-tmp[i,1:2]; vec2<- tmp[i,3]
x[2*(i-1)+1, vec1] <- c(1,-1) ; y[2*(i-1)+1] <- vec2
x[2*i, vec1] <- c(-1,1) ; y[2*i] <- abs(vec2 - 1)
}
x<- x[,-43]
fit<-glmnet(x,y, family = 'binomial', lambda = 0.000001)
gbt_est <- c(fit$beta[,1],0)
gbt_est_mat[k,] <- gbt_est
gbt_rankest <- 44 - rank(gbt_est)
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( gbt_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
if (return_list) perform_list[[k]] <-perform_v
tau_result_vec[k] <- mean(perform_v)
}
if(!return_list) perform_list = NULL
return(list(tau_result_vec = tau_result_vec,
gbt_est_mat = gbt_est_mat,
perform_list = perform_list))
}
######## evaluate performances of the two estimator ####
gbt_fit <- gbt_eval(sc_list, race_mat_test, num_vec_test, cvec,
return_list = TRUE)
gbt_fit
gbt_fit$perform_list[[1]]
gbt_fit$perform_list[[1]]
naive_eval <- function(race_mat_test, num_vec_test, naive_est,
return_list = FALSE)
{
naive_rankest <- 44 - rank(naive_est)
perform_list = list()
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( naive_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
if (return_list) perform_list = perform_v else perform_list = NULL
return(list (tau_result_vec = mean(perform_v), perform_list = perform_list))
}
######## evaluate performances of standard BT estimator ####
tau_result_matrix[seed_v, 1] <- naive_eval(race_mat_test,num_vec_test,
naive_est, return_list = TRUE)
######## evaluate performances of standard BT estimator ####
naive_fit <- naive_eval(race_mat_test,num_vec_test,
naive_est, return_list = TRUE)
tau_result_matrix[seed_v, 1] <- naive_fit$tau_result_vec
naive_fit$perform_list
plot(naive_fit$performa_list, gbt_fit$perform_list)
plot(naive_fit$performa_list, gbt_fit$perform_list[1,])
plot(naive_fit$performa_list, gbt_fit$perform_list[,1])
gbt_fit$perform_list
plot(naive_fit$performa_list, gbt_fit$perform_list[[1]])
gbt_fit$perform_list[[1]]
gbt_fit$perform_list[[1]]
naive_fit$perform_list[[1]]
naive_fit$perform_list
length(gbt_fit$perform_list[[1]])
length(naive_fit$perform_list)
plot(naive_fit$performa_list, gbt_fit$perform_list[[1]])
length(gbt_fit$perform_list[[1]])
length(naive_fit$perform_list)
str(gbt_fit$perform_list[[1]])
str(naive_fit$perform_list)
plot(naive_fit$perform_list, gbt_fit$perform_list[[1]])
abline(a = 0 , b = 1)
plot(naive_fit$perform_list, gbt_fit$perform_list[[1]],
ylab = 'naive', xlab = 'gBT')
plot(naive_fit$perform_list, gbt_fit$perform_list[[1]],
ylab = 'naive', xlab = 'gBT', col = "#FFFFFF10")
plot(naive_fit$perform_list, gbt_fit$perform_list[[1]],
ylab = 'naive', xlab = 'gBT', col = "#00000010")
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[1]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010")
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[1]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010",
pch = 21)
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[1]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010",
pch = 21)
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[1]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010",
pch = 19)
?points
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[1]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010",
pch = 20)
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[2]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010",
pch = 20)
plot(naive_fit$perform_list + rnorm(1919,0,0.02),
gbt_fit$perform_list[[2]] + rnorm(1919,0,0.02),
ylab = 'naive', xlab = 'gBT', col = "#00000010",
pch = 20)
a = naive_fit$perform_list
a = naive_fit$perform_list
b =  gbt_fit$perform_list[[1]]
a==-1
idx =  a==-1
sc_list[[1]]
race_mat_test[[1]]
race_mat_test
race_mat_test[idx,]
race_mat_test[a==-1,]
race_mat_test[b==-1,]
