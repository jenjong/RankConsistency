# central limit theorem 1
n = 1e+4
z = rexp(n)
z
x = c()
idx = sample(1:n,25)
idx
z[idx]
mean(z[idx])
x = c()
for (i in 1:n)
{
idx = sample(1:n,25)
x[i] = sum(z[idx])
}
x
hist(x)
n = 1e+4
z = runif(n)
x = c()
for (i in 1:n)
{
idx = sample(1:n,25)
x[i] = sum(z[idx])
}
hist(x)
n = 1e+4
z = rpois(n)
x = c()
for (i in 1:n)
{
idx = sample(1:n,25)
x[i] = sum(z[idx])
}
hist(x)
# gamma distribution
x = seq(0,10, length = 100)
# gamma distribution
x = seq(0,10, length = 100)
y = dgamma(x, shape = 2, scale = 0.5)
par(mfrow = c(1,2))
plot(x,y, type = 'l', ylim = c(0,.8))
y = dgamma(x, shape = 8, scale = 0.5)
plot(x,y, type = 'l', ylim = c(0,.8))
# gamma distribution
x = seq(0,10, length = 100)
y = dgamma(x, shape = 2, scale = 1)
par(mfrow = c(1,2))
plot(x,y, type = 'l', ylim = c(0,.8))
y = dgamma(x, shape = 2, scale = 2)
plot(x,y, type = 'l', ylim = c(0,.8))
x = seq(0,1, length = 100)
y = dbeta(x, shape1 = 1, shape2 = 1)
par(mfrow = c(1,3))
plot(x,y, type = 'l', ylim = c(0,2.5))
y = dbeta(x, shape1 = 4, shape2 = 2)
plot(x,y, type = 'l', ylim = c(0,2.5))
y = dbeta(x, shape1 = 2, shape2 = 4)
plot(x,y, type = 'l', ylim = c(0,2.5))
# multivariate normal distribution
library(mvtnorm)
library(rgl)
n = 50
mu.vec = c(1,1/2)
mu.vec
Sigma.mat = matrix( c(1,0.5,0.5,2),2,2)
Sigma.mat
x1 = x2 = seq(-3,3, length = n)
z <- matrix(0,n,n)
for (i in 1:n)
for (j in 1:n)
z[i,j] <- dmvnorm(c(x1[i],x2[j]), mu.vec, Sigma.mat)
# multivariate normal distribution
library(mvtnorm)
# multivariate normal distribution
install.packages("mvtnorm")
library(mvtnorm)
library(rgl)
n = 50
mu.vec = c(1,1/2)
Sigma.mat = matrix( c(1,0.5,0.5,2),2,2)
x1 = x2 = seq(-3,3, length = n)
z <- matrix(0,n,n)
for (i in 1:n)
for (j in 1:n)
z[i,j] <- dmvnorm(c(x1[i],x2[j]), mu.vec, Sigma.mat)
contour(x1,x2,z)
contour(x1,x2,z)
mu.vec = c(1,0)
Sigma.mat = matrix( c(1,0.5,0.5,2),2,2)
x1 = x2 = seq(-3,3, length = n)
z <- matrix(0,n,n)
for (i in 1:n)
for (j in 1:n)
z[i,j] <- dmvnorm(c(x1[i],x2[j]), mu.vec, Sigma.mat)
contour(x1,x2,z)
Sigma.mat = matrix( c(1,0.8,0.8,2),2,2)
x1 = x2 = seq(-3,3, length = n)
z <- matrix(0,n,n)
for (i in 1:n)
for (j in 1:n)
z[i,j] <- dmvnorm(c(x1[i],x2[j]), mu.vec, Sigma.mat)
contour(x1,x2,z)
Sigma.mat = matrix( c(1,-0.8,-0.8,2),2,2)
x1 = x2 = seq(-3,3, length = n)
z <- matrix(0,n,n)
for (i in 1:n)
for (j in 1:n)
z[i,j] <- dmvnorm(c(x1[i],x2[j]), mu.vec, Sigma.mat)
contour(x1,x2,z)
persp3d(x1,x2,z, col='green')
y = c(1,1,0,1,1)
dbinom(y, size = 1, prob = 0.5, log = TRUE )
loglike  <- like <- c()
theta.vec <- seq(0,1,length = 100)
for (i in 1:100)
{
theta <- theta.vec[i]
like[i] <- prod(dbinom(y, size = 1, prob = theta, log = FALSE ))
loglike[i] <- sum(dbinom(y, size = 1, prob = theta, log = TRUE ))
}
plot(theta.vec, loglike, type = 'l', col = 'blue')
plot(theta.vec, like, type = 'l', col = 'blue')
plot(theta.vec, loglike, type = 'l', col = 'blue')
### visualizing loglikelihood
n = 100
plot(theta.vec, like, type = 'l', col = 'blue')
plot(theta.vec, loglike, type = 'l', col = 'blue')
# -----------------------------
data(us.cities)
# -----------------------------
if(!require(maps)){install.packages("maps") ;library(maps)}
if(!require(mapdata)){install.packages("mapdata") ;library(mapdata)}
# -----------------------------
data(us.cities)
head(us.cities)
# -----------------------------
map('world', fill = TRUE, col = rainbow(30))
# -----------------------------
map('world', fill = TRUE, col = rainbow(30))
# -----------------------------
map('world', fill = TRUE, col = rainbow(30))
cut(unemp$unemp,
c(0, 2, 4, 6, 8, 10, 100))
unemp$unemp[999]
wm <- ggplot2::map_data('world')
str(wm)
wm %>% dplyr::select(region) %>% unique()
grep( "Uganda", ur$region )
# -----------------------------
ur <- wm %>% dplyr::select(region)%>%unique()
grep( "Uganda", ur$region )
# -----------------------------
map("world", ur$region[grep( "Uganda", ur$region )],
fill = T,
col = "blue")
# -----------------------------
if(!require(mapplots)){install.packages("mapplots") ;library(mapplots)}
if(!require(ggmap)){install.packages("ggmap") ;library(ggmap)}
if(!require(mapdata)){install.packages("mapdata") ;library(mapdata)}
map('worldHires', 'South Korea')
geocode('seoul')
seoul_loc = geocode('Seoul')
seoul_loc
# -----------------------------
if(!require(mapplots)){install.packages("mapplots") ;library(mapplots)}
if(!require(ggmap)){install.packages("ggmap") ;library(ggmap)}
if(!require(mapdata)){install.packages("mapdata") ;library(mapdata)}
seoul_loc = geocode('seoul')
seoul_loc
busan_loc = geocode('Busan')
busan_loc
seoul_loc
seoul_loc = geocode('seoul')
seoul_loc
seoul_loc$lon
seoul_loc$lat
add.pie(z=1:2,labels = c('a','b'),
x = seoul_loc$lon, y = seoul_loc$lat, radius = 0.5)
add.pie(z=4:3,labels = c('a','b'),
x = busan_loc$lon, y = busan_loc$lat, radius = 0.5)
abline(h = 38)
rm(list = ls()); gc(reset = T)
# -------------------------------------------
if(!require(OpenStreetMap)){install.packages("OpenStreetMap"); library(OpenStreetMap)}
if(!require(ggplot2)){install.packages("ggplot2"); library(ggplot2)}
# -------------------------------------------
map = OpenStreetMap::openmap(upperLeft = c(43, 119), lowerRight = c(33, 134),
type = 'bing')
# -------------------------------------------
if(!require(OpenStreetMap)){install.packages("OpenStreetMap"); library(OpenStreetMap)}
if(!require(ggplot2)){install.packages("ggplot2"); library(ggplot2)}
# -------------------------------------------
map = OpenStreetMap::openmap(upperLeft = c(43, 119), lowerRight = c(33, 134),
type = 'bing')
plot(map)
autoplot(map)
# -------------------------------------------
nm = c("osm", "mapbox", "stamen-toner",
"stamen-watercolor", "esri", "esri-topo",
"nps", "apple-iphoto", "osm-public-transport")
par(mfrow=c(3,3),  mar=c(0, 0, 0, 0), oma=c(0, 0, 0, 0))
for(i in 1:length(nm)){
map <- openmap(c(43,119),
c(33,134),
minNumTiles = 3,
type = nm[i])
plot(map, xlab = paste(nm[i]))
}
if (!require(sp)) {install.packages('sp'); library(sp)}
if (!require(gstat)) {install.packages('gstat'); library(gstat)}
if (!require(automap)) {install.packages('automap'); library(automap)}
if (!require(rgdal)) {install.packages('rgdal'); library(rgdal)}
if (!require(e1071)) {install.packages('e1071'); library(e1071)}
if (!require(dplyr)) {install.packages('dplyr'); library(dplyr)}
if (!require(lattice)) {install.packages('lattice'); library(lattice)}
if (!require(viridis)) {install.packages('viridis'); library(viridis)}
# -------------------------------------------
seoul032823 <- read.csv ("seoul032823.csv")
getwd()
# -------------------------------------------
seoul032823 <- read.csv ("./data/seoul032823.csv")
head(seoul032823)
# -------------------------------------------
skorea <- raster::getData(name ="GADM", country= "KOR", level=2)
# skorea <- readRDS("KOR_adm2.rds")
head(skorea,2)
class(skorea)
head(skorea@polygons[[1]]@Polygons[[1]]@coords, 3)
# -------------------------------------------
if (!require(broom)) {install.packages('broom'); library(broom)}
skorea <- broom::tidy(skorea)
class(skorea)
head(skorea,3)
ggplot() + geom_map(data= skorea, map= skorea,
aes(map_id=id,group=group),fill=NA, colour="black")
ggplot() + geom_map(data= skorea, map= skorea,
aes(map_id=id,group=group),fill=NA, colour="black") +
geom_point(data=seoul032823, aes(LON, LAT, col = PM10),alpha=0.7)
Sys.info
Sys.info()
x = rnorm(100)
y = 2*x + rnorm(length(x))
source('~/.active-rstudio-document', echo=TRUE)
x = rnorm(100)
y = 2*x + rnorm(length(x))
plot(x,y, pch = 19)
abline(a = 0, b  = 2, col = 'blue', lwd = 2)
lm(x,y)
lm(y~x )
fit = lm(y~x )
plot(fit)
30*16
45*16
heat.colors(300)
unique(heat.colors(300))
strsplit(“abc.b”, split = “\\.”)
strsplit('abc.b', split = '\\.')
is.na(3)
rm(list = ls())
matrix(sample(c(1,-1),100, replace = T), 10, 10)
x1 = matrix(sample(c(1,-1),100, replace = T), 10, 10)
x2 = c(sample(2:9,1), sample(2:9,1))
x2
x1[(x2[1]-1):(x2[1]+1), (x2[2]-1):(x2[2]+1)]
sum(x1[(x2[1]-1):(x2[1]+1), (x2[2]-1):(x2[2]+1)])
sign(sum(x1[(x2[1]-1):(x2[1]+1), (x2[2]-1):(x2[2]+1)]))
y = sign(sum(x1[(x2[1]-1):(x2[1]+1), (x2[2]-1):(x2[2]+1)]))
2000*70
2000*70/1000
70/200
40*10
40*10*10
2.5*24
200/200
10*2.5
10*0.25
10*24
10*24/4
180*6
# python nltk package used stopword dic
# R tm package stopwords
install.packages("tm")
180*3
180*3*4
16*1000
16*1000/3600
16*1000/3600
16*180
4*250
16*180
16*180/5
16*180/5/8
1600
800
2400 + 16*180
16*180
180*8
0.8*450
180*8
180*8*2
250*4
180*8
450*1.2
4*450
4*250
16*180
450*1.2
450*1.2+ 8*180
450*4+ 4*250 + 16 *180
450 *4
450 *4 + 250 *4
450 *4 + 250 *4 + 180*8
450 *4 + 250 *4 + 180*16
5680*0.15
rm(list = ls())
gc(reset = T)
if(!require(data.table)) install.packages("data.table")
if(!require(dplyr)) install.packages("dplyr")
require(data.table)
require(dplyr)
args = commandArgs(TRUE)
if (length(args)==0) {
stop("At least one argument must be supplied (input file).\n", call.=FALSE)
} else {
print("args-----")
mem_input_filename <- args[1]
mem_output_filename <- args[2]
print(mem_input_filename)
print(mem_output_filename)
}
mem_output_filename = gsub('.csv', '', mem_output_filename)
450*0.5
450*4 + 250*4 + 180*16
(450*4 + 250*4 + 180*16 )*0.26
(450*4 + 250*4 + 180*16 )*0.25
360 + 125
5680-1476
225*8
4204-1800
2400/8
300/6
225*0.75
]y]'y];y;r'h;o'cdlc;lc'z[ s ]
's'
''
rm(list = ls())
setwd('C:/Users/Jeon/Documents/GitHub/RankConsistency')
load("Real_BT_gBT2_cv5_all_data.rdata")
gBT2_est_rank
BT_est_rank
which(BT_est_rank==9)
gBT2_est_rank[40]
which(BT_est_rank==4)
gBT2_est_rank[12]
sel_idx = which(BT_est_rank <=13)
which(BT_est_rank==9)
gBT2_est_rank[40]
which(BT_est_rank==4)
gBT2_est_rank[12]
sel_idx = which(BT_est_rank <=13)
source('./lib/car_lib.R')
source('./lib/lib_rank.R')
source('./lib/sim.R')
source('./lib/real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
rdata <- rbind(rdata, rdata)
max_k = 4
cvec_r <- seq(0, max_k, by = 2)
file_idx = 1
inner_iter = 100
seed_v = 1
result_matrix_kendall = matrix(0,inner_iter, length(cvec_r)+1)
result_matrix_DCG = matrix(0,inner_iter, length(cvec_r)+1)
result_list = list()
result_list$naive = vector(mode = 'list', length = inner_iter)
result_list$gbt = vector(mode = 'list', length = inner_iter)
cat("iteration::", seed_v, '\n')
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sc_list = vector(mode ='list', length = max_k)
## 논문에 나온대로 7:3으로 뽑음.
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*1)))
# cross validation : 여기서 sample 다시 생성해야 함!
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qmat = Qmat_fit$Qmat
sum(Qmat[12,-sel_idx])
sum(Qmat[12,sel_idx])
sum(Qmat[40,-sel_idx])
sum(Qmat[40,])
Gmat_hat <- Qmat_fit$Gmat_hat
Wmat <- Qmat_fit$Wmat
Gmat_hat[40,sel_idx]
Gmat_hat[12,sel_idx]
cbind(Gmat_hat[40,sel_idx], Gmat_hat[12,sel_idx])
cbind(Wmat[40,sel_idx], Wmat[12,sel_idx])
cbind(Wmat[40,sel_idx], Wmat[12,sel_idx])
cbind(Qmat[40,sel_idx], Qmat[12,sel_idx])
cbind(Wmat[40,sel_idx], Wmat[12,sel_idx])/
cbind(Qmat[40,sel_idx], Qmat[12,sel_idx])
names(Qpmat)
sum(Wmat[40,sel_idx])/sum(Qmat[40,sel_idx])
sum(Wmat[12,sel_idx])/sum(Qmat[12,sel_idx])
sum(Wmat[12,])/sum(Qmat[12,])
Qmat
rm(list = ls())
setwd('C:/Users/Jeon/Documents/GitHub/RankConsistency')
load("Real_BT_gBT2_cv5_all_data.rdata")
gBT2_est_rank
BT_est_rank
#
which(BT_est_rank==9)
gBT2_est_rank[40]
which(BT_est_rank==4)
gBT2_est_rank[12]
sel_idx = which(BT_est_rank <=13)
source('./lib/car_lib.R')
source('./lib/lib_rank.R')
source('./lib/sim.R')
source('./lib/real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
rdata <- rbind(rdata, rdata)
max_k = 0
cvec_r <- seq(0, max_k, by = 2)
file_idx = 1
cat("iteration::", seed_v, '\n')
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*1)))
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qmat = Qmat_fit$Qmat
rm(list = ls())
setwd('C:/Users/Jeon/Documents/GitHub/RankConsistency')
load("Real_BT_gBT2_cv5_all_data.rdata")
gBT2_est_rank
BT_est_rank
#
which(BT_est_rank==9)
gBT2_est_rank[40]
which(BT_est_rank==4)
gBT2_est_rank[12]
sel_idx = which(BT_est_rank <=13)
source('./lib/car_lib.R')
source('./lib/lib_rank.R')
source('./lib/sim.R')
source('./lib/real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
rdata <- rbind(rdata, rdata)
max_k = 0
cvec_r <- seq(0, max_k, by = 2)
file_idx = 1
cat("iteration::", seed_v, '\n')
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(1)
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*1)))
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qmat = Qmat_fit$Qmat
rm(list = ls())
setwd('C:/Users/Jeon/Documents/GitHub/RankConsistency')
load("Real_BT_gBT2_cv5_all_data.rdata")
gBT2_est_rank
BT_est_rank
#
which(BT_est_rank==9)
gBT2_est_rank[40]
which(BT_est_rank==4)
gBT2_est_rank[12]
sel_idx = which(BT_est_rank <=13)
source('./lib/car_lib.R')
source('./lib/lib_rank.R')
source('./lib/sim.R')
source('./lib/real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
rdata <- rbind(rdata, rdata)
max_k = 0
cvec_r <- 0
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*1)))
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qmat = Qmat_fit$Qmat
sum(Qmat[12,-sel_idx])
sum(Qmat[12,sel_idx])
sum(Qmat[40,-sel_idx])
sum(Qmat[40,])
Gmat_hat <- Qmat_fit$Gmat_hat
Wmat <- Qmat_fit$Wmat
Gmat_hat[40,sel_idx]
Gmat_hat[12,sel_idx]
cbind(Gmat_hat[40,sel_idx], Gmat_hat[12,sel_idx])
cbind(Wmat[40,sel_idx], Wmat[12,sel_idx])
cbind(Wmat[40,sel_idx], Wmat[12,sel_idx])
cbind(Qmat[40,sel_idx], Qmat[12,sel_idx])
cbind(Wmat[40,sel_idx], Wmat[12,sel_idx])/
cbind(Qmat[40,sel_idx], Qmat[12,sel_idx])
names(Qpmat)
sum(Wmat[40,sel_idx])/sum(Qmat[40,sel_idx])
sum(Wmat[12,sel_idx])/sum(Qmat[12,sel_idx])
sum(Wmat[12,])/sum(Qmat[12,])
