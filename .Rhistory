nvec1 = Qpmat.c1[i1,]
nvec2 = Qpmat.c1[i2,]
idx1 = which(nvec1 == 0 | nvec2 == 0)
idx2  =  setdiff( idx1, c(i1, i2))
nvec3 = (nvec1[-idx1]+nvec2[-idx1])/2
Qpmat.c2[i1,-idx1] = Qpmat.c2[i2,-idx1] = nvec3
if (length(idx2)>0)  Qpmat.c2[i1,idx2] =  Qpmat.c2[i2,idx2] = 0
Qpmat.c2[,i1] <- Qpmat.c2[i1,]
Qpmat.c2[,i2] <- Qpmat.c2[i2,]  ## Qpmat.c2 : symm matrix
#idx3 <- sort( union(intersect( setdiff(1:p, idx1), setdiff(1:p, idx2) ),  c(i1, i2)) )
## find V_jk(maximum connected set)
i1i2_adj_matrix = matrix(as.integer(Qpmat.c2>0) , p , p)  ## adjacency matrix
i1i2_graph = graph_from_adjacency_matrix(i1i2_adj_matrix ,
mode="undirected" , weighted=NULL) ## make a graph
i1i2_clusters = clusters(i1i2_graph)$mem ## clustering using adj matrix
if (i1i2_clusters[i1] != i1i2_clusters[i2]){  ## i1과 i2가 다른 connected 되지 않은 경우
cat('   k:',k-1,', ',i1,'and',i2, 'is not connected!!\n')
idx = idx + 1
next
}
## idx3 : edge index set of V_jk
idx3 = sort(which(i1i2_clusters %in% i1i2_clusters[i1]))
#########################################
## computing gBT estimator
#########################################
wmat <- Qpmat.c2[idx3,idx3]*Gmat_hat[idx3, idx3]
wmat = t(wmat)
pp <- length(idx3)
wvec = wmat[ - (1 + ( 0:(pp-1) ) *(pp+1))]
xx = matrix(0, pp*(pp-1), pp)
yy = rep(0, pp*(pp-1) )
ix = 1
for (i in 1:pp)
{
for (j in 1:pp)
{
if (i == j) next
jx1 = min(i,j)
jx2 = max(i,j)
xx[ix,jx1] = 1; xx[ix,jx2] = -1
if (i<j) yy[ix] = 1
ix = ix + 1
}
}
xx = xx[,-pp]
try.fit <- try(fit <- glmnet(xx, yy, family = 'binomial',
intercept = FALSE, weights = wvec,
lambda = 0.0001, alpha = 0, standardize = F,
thresh = 1e-09),
silent = T)
if (class(try.fit)[1] == 'try-error')
{
idx = idx + 1
next
}
est = c(fit$beta[,1],0)
result[idx, 1:2] = c(i1, i2)
if( est[which(idx3==i1)] > est[which(idx3==i2)]) result[idx, 3] = 1
idx = idx + 1
}
}
sc_list[[k]] <- result
}
return( sc_list )
}
naive_eval <- function(race_mat_test, num_vec_test, naive_est)
{
naive_rankest <- 44 - rank(naive_est)
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( naive_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
return(mean(perform_v))
}
gbt_eval <- function(sc_list,race_mat_test, num_vec_test, cvec)
{
tau_result_vec <- rep(0, length(cvec))
k = 0
for (k in 1:length(cvec))
{
tmp<-sc_list[[k]]
tmp <-tmp[tmp[,1]!=0, 1:3]
p_set <-unique(c(tmp[,1:2]))
if (length(p_set) != 43)
{
tau_result_vec[k] <- NA
next
}
x <- matrix(0, nrow(tmp)*2, 43)
y <- rep(0, nrow(tmp)*2)
for ( i in 1:nrow(tmp))
{
vec1<-tmp[i,1:2]; vec2<- tmp[i,3]
x[2*(i-1)+1, vec1] <- c(1,-1) ; y[2*(i-1)+1] <- vec2
x[2*i, vec1] <- c(-1,1) ; y[2*i] <- abs(vec2 - 1)
}
x<- x[,-43]
fit<-glmnet(x,y, family = 'binomial', lambda = 0.000001)
gbt_est <- c(fit$beta[,1],0)
gbt_rankest <- 44 - rank(gbt_est)
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( gbt_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
tau_result_vec[k] <- mean(perform_v)
}
return(tau_result_vec)
}
rm(list = ls())
gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
library(igraph)
library(MASS)
source('car_lib.R')
source('lib_rank.R')
source('sim.R')
source('real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
max_k = 15
cvec_r <- seq(0, max_k, by = 5)
file_idx = 1
inner_iter = 10
tau_result_matrix <- matrix(0, inner_iter, max_k + 2)
seed_v = 1
cvec_r
seed_v = 1
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.7)))  ## 논문에 나온대로 7:3으로 뽑음.
# cross validation : 여기서 sample 다시 생성해야 함!
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
##########################################################
######## naive BT fit
naive_est<- naive_btFunc(x,y, Qpmat, Gmat_hat)
##########################################################
######## gBT fit
###############################
# set weight-vector
cvec <- cvec_r/n*2 ## cvec : threshold c vector
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
race_mat_test<- as.matrix(rdata[-sample_idx,18:33])
num_vec_test <- rdata$V1[-sample_idx]
######## evaluate performances of standard BT estimator ####
tau_result_matrix[seed_v, 1] <- naive_eval(race_mat_test,num_vec_test,
naive_est)
######## evaluate performances of the two estimator ####
tau_result_matrix[seed_v, 2:(length(cvec)+1)]<-
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
report_v <- colMeans(tau_result_matrix[1:seed_v,,drop = F], na.rm = T )
cat('now::::\n')
cat(round(report_v,5),'\n')
######## evaluate performances of the two estimator ####
tau_result_matrix[seed_v, 2:(length(cvec)+1)]<-
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
sc_list
race_mat_test
num_vec_test
cvec
tau_result_vec <- rep(0, length(cvec))
tau_result_vec
k = 0
length(sc_list)
k=4
tmp<-sc_list[[k]]
tmp <-tmp[tmp[,1]!=0, 1:3]
p_set <-unique(c(tmp[,1:2]))
if (length(p_set) != 43)
{
tau_result_vec[k] <- NA
next
}
p_set
length(p_set)
length(p_set) != 43
tau_result_vec <- rep(0, length(cvec))
for (k in 1:length(cvec))
{
tmp<-sc_list[[k]]
tmp <-tmp[tmp[,1]!=0, 1:3]
p_set <-unique(c(tmp[,1:2]))
if (length(p_set) != 43)
{
tau_result_vec[k] <- NA
next
}
x <- matrix(0, nrow(tmp)*2, 43)
y <- rep(0, nrow(tmp)*2)
for ( i in 1:nrow(tmp))
{
vec1<-tmp[i,1:2]; vec2<- tmp[i,3]
x[2*(i-1)+1, vec1] <- c(1,-1) ; y[2*(i-1)+1] <- vec2
x[2*i, vec1] <- c(-1,1) ; y[2*i] <- abs(vec2 - 1)
}
x<- x[,-43]
fit<-glmnet(x,y, family = 'binomial', lambda = 0.000001)
gbt_est <- c(fit$beta[,1],0)
gbt_rankest <- 44 - rank(gbt_est)
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( gbt_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
tau_result_vec[k] <- mean(perform_v)
}
tau_result_vec
gbt_eval <- function(sc_list,race_mat_test, num_vec_test, cvec)
{
tau_result_vec <- rep(0, length(cvec))
for (k in 1:length(cvec))
{
tmp<-sc_list[[k]]
tmp <-tmp[tmp[,1]!=0, 1:3]
p_set <-unique(c(tmp[,1:2]))
if (length(p_set) != 43)
{
tau_result_vec[k] <- NA
next
}
x <- matrix(0, nrow(tmp)*2, 43)
y <- rep(0, nrow(tmp)*2)
for ( i in 1:nrow(tmp))
{
vec1<-tmp[i,1:2]; vec2<- tmp[i,3]
x[2*(i-1)+1, vec1] <- c(1,-1) ; y[2*(i-1)+1] <- vec2
x[2*i, vec1] <- c(-1,1) ; y[2*i] <- abs(vec2 - 1)
}
x<- x[,-43]
fit<-glmnet(x,y, family = 'binomial', lambda = 0.000001)
gbt_est <- c(fit$beta[,1],0)
gbt_rankest <- 44 - rank(gbt_est)
perform_v <- rep(0, length(num_vec_test))
for (i in 1:length(num_vec_test))
{
obs_cars <- race_mat_test[i,][1:num_vec_test[i]]
rank_true <- 1:length(obs_cars)
rank_hat  <- order( gbt_est[obs_cars], decreasing = T)
perform_v[i] <- cor(rank_true, rank_hat, method = "kendall")
}
tau_result_vec[k] <- mean(perform_v)
}
return(tau_result_vec)
}
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
colMeans(tau_result_matrix[1:seed_v,,drop = F], na.rm = T )
cvec_r
rm(list = ls())
gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
library(igraph)
library(MASS)
source('car_lib.R')
source('lib_rank.R')
source('sim.R')
source('real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
max_k = 15
cvec_r <- seq(0, max_k, by = 5)
file_idx = 1
inner_iter = 10
tau_result_matrix <- matrix(0, inner_iter, length(cvec_r)+1)
seed_v = 1
rm(list = ls())
gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
library(igraph)
library(MASS)
source('car_lib.R')
source('lib_rank.R')
source('sim.R')
source('real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
max_k = 15
cvec_r <- seq(0, max_k, by = 5)
file_idx = 1
inner_iter = 10
tau_result_matrix <- matrix(0, inner_iter, length(cvec_r)+1)
seed_v = 1
for ( seed_v in 1:inner_iter)
{
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.7)))  ## 논문에 나온대로 7:3으로 뽑음.
# cross validation : 여기서 sample 다시 생성해야 함!
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
##########################################################
######## naive BT fit
naive_est<- naive_btFunc(x,y, Qpmat, Gmat_hat)
##########################################################
######## gBT fit
###############################
# set weight-vector
cvec <- cvec_r/n*2 ## cvec : threshold c vector
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
race_mat_test<- as.matrix(rdata[-sample_idx,18:33])
num_vec_test <- rdata$V1[-sample_idx]
######## evaluate performances of standard BT estimator ####
tau_result_matrix[seed_v, 1] <- naive_eval(race_mat_test,num_vec_test,
naive_est)
######## evaluate performances of the two estimator ####
tau_result_matrix[seed_v, 2:(length(cvec)+1)]<-
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
report_v <- colMeans(tau_result_matrix[1:seed_v,,drop = F], na.rm = T )
cat('now::::\n')
cat(round(report_v,5),'\n')
}
tau_result_matrix
boxplot(tau_result_matrix)
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.7)))  ## 논문에 나온대로 7:3으로 뽑음.
sid <- sample(1:5, length(sample_idx), replace = TRUE)
cv_k = 1
sample_idx_cvtr<- sample_idx[sid!=cv_k]
race_mat <- as.matrix(rdata[sample_idx_cvtr,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx_cv]  ## 각 게임마다 참여한 유저 수
num_vec<- rdata$V1[sample_idx_cvtr]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
cvec_r <- cvec/n*2
#cv
cvec_r <- seq(0, max_k, by = 5)
cvec <- cvec_r/n*2
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
sample_idx_cvte<- sample_idx[sid==cv_k]
sample_idx_cvte
cv_k
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
sample_idx_cvte<- sample_idx[sid==cv_k]
race_mat_test<- as.matrix(rdata[sample_idx_cvte,18:33])
num_vec_test <- rdata$V1[sample_idx_cvte]
naive_eval(race_mat_test,num_vec_test,
naive_est)
cvec_r
cvec
length(sc_list)
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
sample_idx_cvtr<- sample_idx[sid!=cv_k]
race_mat <- as.matrix(rdata[sample_idx_cvtr,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx_cvtr]  ## 각 게임마다 참여한 유저 수
num_vec
cv_k
sample_idx[sid!=cv_k]
length(sample_idx[sid!=cv_k])
length(sample_idx)
sid <- sample(1:10, length(sample_idx), replace = TRUE)
cv_k = 1
sample_idx_cvtr<- sample_idx[sid!=cv_k]
race_mat <- as.matrix(rdata[sample_idx_cvtr,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx_cvtr]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
cvec <- cvec_r/n*2
n
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
sample_idx_cvte<- sample_idx[sid==cv_k]
race_mat_test<- as.matrix(rdata[sample_idx_cvte,18:33])
num_vec_test <- rdata$V1[sample_idx_cvte]
######## evaluate performances of standard BT estimator ####
tau_result_matrix[seed_v, 2:(length(cvec)+1)]<-
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
max_k
cvec_r <- seq(0, max_k, by = 5)
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.7)))  ## 논문에 나온대로 7:3으로 뽑음.
sid <- sample(1:5, length(sample_idx), replace = TRUE)
cv_k = 1
cv_err<- NULL
#cv
cvec_r <- seq(0, max_k, by = 5)
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.7)))  ## 논문에 나온대로 7:3으로 뽑음.
sid <- sample(1:5, length(sample_idx), replace = TRUE)
cv_k = 1
cv_err<- NULL
for (cv_k in 1:5)
{
sample_idx_cvtr<- sample_idx[sid!=cv_k]
race_mat <- as.matrix(rdata[sample_idx_cvtr,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx_cvtr]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
cvec <- cvec_r/n*2
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
sample_idx_cvte<- sample_idx[sid==cv_k]
race_mat_test<- as.matrix(rdata[sample_idx_cvte,18:33])
num_vec_test <- rdata$V1[sample_idx_cvte]
######## evaluate performances of standard BT estimator ####
tmp = gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
cv_err <- rbind(cv_err, tmp)
}
cv_err
colMeans(cv_err,na.rm = T)
rm(list = ls())
gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
library(igraph)
library(MASS)
source('car_lib.R')
source('lib_rank.R')
source('sim.R')
source('real_lib.R')
require('glmnet')
rdata<-read.csv('racing_data.csv', header=F)
max_k = 15
cvec_r <- seq(0, max_k, by = 5)
file_idx = 1
inner_iter = 10
tau_result_matrix <- matrix(0, inner_iter, length(cvec_r)+1)
seed_v = 1
for ( seed_v in 1:inner_iter)
{
seed_v_i = (file_idx -1)*inner_iter + seed_v
set.seed(seed_v_i)
sc_list = vector(mode ='list', length = max_k)
sample_idx <- sort( sample(1:nrow(rdata), trunc(nrow(rdata)*0.8)))  ## 논문에 나온대로 7:3으로 뽑음.
# cross validation : 여기서 sample 다시 생성해야 함!
race_mat <- as.matrix(rdata[sample_idx,18:33])   ## train set의 각 게임당 선택 차종
num_vec<- rdata$V1[sample_idx]  ## 각 게임마다 참여한 유저 수
Qmat_fit <-QmatFunc(race_mat, num_vec)
Qpmat = Qmat_fit$Qpmat
Gmat_hat = Qmat_fit$Gmat_hat
x = Qmat_fit$x
y = Qmat_fit$y
n = Qmat_fit$n
##########################################################
######## naive BT fit
naive_est<- naive_btFunc(x,y, Qpmat, Gmat_hat)
##########################################################
######## gBT fit
###############################
# set weight-vector
cvec <- cvec_r/n*2 ## cvec : threshold c vector
sc_list <- sc_listFun(cvec, Qpmat, Gmat_hat)
##### end of pairwise learning ######
### make the test set #####
## test set의 각 게임당 선택 차종
race_mat_test<- as.matrix(rdata[-sample_idx,18:33])
num_vec_test <- rdata$V1[-sample_idx]
######## evaluate performances of standard BT estimator ####
tau_result_matrix[seed_v, 1] <- naive_eval(race_mat_test,num_vec_test,
naive_est)
######## evaluate performances of the two estimator ####
tau_result_matrix[seed_v, 2:(length(cvec)+1)]<-
gbt_eval(sc_list, race_mat_test, num_vec_test, cvec)
report_v <- colMeans(tau_result_matrix[1:seed_v,,drop = F], na.rm = T )
cat('now::::\n')
cat(round(report_v,5),'\n')
}
boxplot(tau_result_matrix)
