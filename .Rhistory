# load("table2.rdata")
i = 1
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 2
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 3
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 4
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 5
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
# load("table2.rdata")
i = 6
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
rm(list=ls())
library(Matrix)
library(Rcpp)
library(inline)
library(RcppArmadillo)
library(genlasso)
library(Rglpk); library("MethylCapSig")
sourceCpp('D:/Jeon/rcode/ComLasso/library/inner.cpp')
source("D:/Jeon/rcode/ComLasso/library/ComLassoC.R")
# table 1
para_vec = list()
para_vec[[1]] <- c(50,200)
para_vec[[2]] <- c(50,500)
para_vec[[3]] <- c(50,1000)
para_vec[[4]] <- c(100,200)
para_vec[[5]] <- c(100,500)
para_vec[[6]] <- c(100,1000)
runtime.list <- vector(mode="list",length=length(para_vec))
Rnum <- 20
ll = 1
for(ll in 1:length(para_vec))
{
n = para_vec[[ll]][1]
pk <- para_vec[[ll]][-1]
idx_gs <- cumsum(pk)-pk+1
idx_ge <- cumsum(pk)
idx_gs_r  = idx_gs - 0:(length(pk)-1)
idx_ge_r  = idx_ge - 1:length(pk)
p = sum(pk)
B_list = list()
for (j in 1:length(pk))
{
sigma <- 0.5^(abs(outer(1:(pk[j]-1),1:(pk[j]-1),"-")))
svdFit <- svd(sigma)
B = diag(svdFit$d)^0.5 %*% t(svdFit$v)
if ( j == 1)
{
mm<-rep(0,pk[j]-1); mm[1:5]<- log(0.5*pk[j])
}
B_list[[j]] = B
}
runtime<-matrix(0,Rnum,2)
colnames(runtime) <-c("comlasso", "genlasso")
r = 1
for(r in 1:Rnum)
{
set.seed(r)
w = NULL
z = NULL
for (j in 1:length(pk))
{
B <- B_list[[j]]
tmp = matrix(rnorm(n*(pk[j]-1)), n, pk[j]-1) %*% B
if (j == 1) tmp = tmp + mm
tmpU = cbind(exp(tmp), 1)
z = cbind(z, sweep(tmpU, 1, rowSums(tmpU), FUN = "/") )
w <- cbind(w, tmp)
}
b <- rep(0,p-length(pk))
b[1:5] <- c(1,-0.8,0.6,0,0)
b[6:8] <- c(-1.5, -0.5, 1.2)
y <- drop(w %*% b)+rnorm(n,0,0.5^2)
# reparametrization for genlasso
rX = X = log(z)
Cm <- diag(1,p)
for (i in 1:length(pk))
{
sidx = idx_gs[i]:idx_ge[i]
for (j in sidx) rX[,j] = rX[,j] - rX[,idx_ge[i]]
Cm[idx_ge[i],sidx] <- 1
}
rX <- rX[,-(idx_ge)]
Cm <- Cm[,-(idx_ge)]
Cm <- cbind(0,Cm)
rX <- cbind(1, rX)
#if (p>n) Cm <- Matrix(Cm, sparse = TRUE)
runtime[r,1] <- system.time(cfun2 <- comLassoC(X,y,pk=pk,lam_min=0,
tol=1e-08,KKT_check=FALSE) # Prof. Jeon
)[3]
runtime[r,2]<-system.time(gfun<-genlasso(y=y,X=rX,D=Cm,approx=FALSE,
maxsteps=length(cfun2$lambda_vec)+1,
minlam=0,
rtol=1e-07,btol=1e-07,eps=1e-4,
verbose=FALSE,svd=FALSE))[3]
cat(runtime[r,],"\n")
}
runtime.list[[ll]] <- runtime
}
# load("table2.rdata")
i = 1
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
para_vec
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 1
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 2
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 3
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 1
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 2
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 3
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 4
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 5
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 6
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
para_vec
save.image("table1.rdata")
rm(list=ls())
library(Matrix)
library(Rcpp)
library(inline)
library(RcppArmadillo)
library(genlasso)
library(Rglpk); library("MethylCapSig")
sourceCpp('D:/Jeon/rcode/ComLasso/library/inner.cpp')
source("D:/Jeon/rcode/ComLasso/library/ComLassoC.R")
# table 2
para_vec = list()
para_vec[[1]] <- c(50,rep(100,10))
para_vec[[2]] <- c(50,rep(20,50))
para_vec[[3]] <- c(50,rep(10,100))
para_vec[[4]] <- c(100,rep(100,10))
para_vec[[5]] <- c(100,rep(20,50))
para_vec[[6]] <- c(100,rep(10,100))
runtime.list <- vector(mode="list",length=length(para_vec))
Rnum <- 20
ll = 1
for(ll in 1:length(para_vec))
{
n = para_vec[[ll]][1]
pk <- para_vec[[ll]][-1]
idx_gs <- cumsum(pk)-pk+1
idx_ge <- cumsum(pk)
idx_gs_r  = idx_gs - 0:(length(pk)-1)
idx_ge_r  = idx_ge - 1:length(pk)
p = sum(pk)
B_list = list()
for (j in 1:length(pk))
{
sigma <- 0.5^(abs(outer(1:(pk[j]-1),1:(pk[j]-1),"-")))
svdFit <- svd(sigma)
B = diag(svdFit$d)^0.5 %*% t(svdFit$v)
if ( j == 1)
{
mm<-rep(0,pk[j]-1); mm[1:5]<- log(0.5*pk[j])
}
B_list[[j]] = B
}
runtime<-matrix(0,Rnum,2)
colnames(runtime) <-c("comlasso", "genlasso")
r = 1
for(r in 1:Rnum)
{
set.seed(r)
w = NULL
z = NULL
for (j in 1:length(pk))
{
B <- B_list[[j]]
tmp = matrix(rnorm(n*(pk[j]-1)), n, pk[j]-1) %*% B
if (j == 1) tmp = tmp + mm
tmpU = cbind(exp(tmp), 1)
z = cbind(z, sweep(tmpU, 1, rowSums(tmpU), FUN = "/") )
w <- cbind(w, tmp)
}
b <- rep(0,p-length(pk))
b[1:5] <- c(1,-0.8,0.6,0,0)
b[6:8] <- c(-1.5, -0.5, 1.2)
y <- drop(w %*% b)+rnorm(n,0,0.5^2)
# reparametrization for genlasso
rX = X = log(z)
Cm <- diag(1,p)
for (i in 1:length(pk))
{
sidx = idx_gs[i]:idx_ge[i]
for (j in sidx) rX[,j] = rX[,j] - rX[,idx_ge[i]]
Cm[idx_ge[i],sidx] <- 1
}
rX <- rX[,-(idx_ge)]
Cm <- Cm[,-(idx_ge)]
Cm <- cbind(0,Cm)
rX <- cbind(1, rX)
#if (p>n) Cm <- Matrix(Cm, sparse = TRUE)
runtime[r,1] <- system.time(cfun2 <- comLassoC(X,y,pk=pk,lam_min=0,
tol=1e-08,KKT_check=FALSE) # Prof. Jeon
)[3]
runtime[r,2]<-system.time(gfun<-genlasso(y=y,X=rX,D=Cm,approx=FALSE,
maxsteps=length(cfun2$lambda_vec)+1,
minlam=0,
rtol=1e-07,btol=1e-07,eps=1e-4,
verbose=FALSE,svd=FALSE))[3]
cat(runtime[r,],"\n")
}
runtime.list[[ll]] <- runtime
}
n
p
pk
save.image("table2.rdata")
getwd()
i = 1
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 2
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 3
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 4
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 5
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
i = 6
apply(runtime.list[[i]],2, mean)
apply(runtime.list[[i]],2, sd)/sqrt(20)
library(readr)
wine <- read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data",
col_names = FALSE)
View(wine)
TRUE & FALSE
TRUE | FALSE
!TRUE
a = 0L
a[2] = 1
a
typeof[1]
typeof(a[1])
a = 0L
a[2] = 1
typeof(a[1])
a = matrix(1:10,5,2)
b = a[,-1]
class(b)
class(a)
class(b)
a = matrix(1:10,5,2)
b = a[,-1, drop = FALSE]
class(b)
a = matrix(1:10,5,2)
b = c(a)
class(b)
str(b)
a = list()
for (i in 1:5) a[[i]] = i
b = unlist(a)
b
a = 1:3
b = as.matrix(a)
b
a = matrix(1:10,5,2)
b = as.data.frame(a)
b = unclass(b)
b
class(b)
as.double(1L)
as.numeric
?as.factor
a = c("tommy", "jimmy", "jane")
b = as.factor(a)
b
str(b)
c(b)
typeof(c(b)[1])
y
install.packages('xlsx')
1/3.3754
30/3.3754
1.6/3.3754
mtcars
mtcars$mpg*1.6/3.78
install.packages("FNN")
install.packages("scatterplot3d")
plot(~mpg+disp+drat+wt,data=mtcars,
main="Simple Scatterplot Matrix")
plot(x,y, type = "b", lty = 3, main = "y = x^2")
attach(mtcars)
head(mtcars, n = 2)
plot(mpg ~ disp, data = mtcars)
plot(hp ~ disp, data = mtcars)
x = rnorm(100)
y = 2+2*x + rnorm(100)
plot(x,y, main = "plot (x-y)")
x = seq(-2,2, length = 10)
y = x^2
par(mfrow = c(2,2))
plot(x,y, type = 'p', main = "(a)")
plot(x,y, type = 'b', main = "(b)")
plot(x,y, type = 'l', main = "(c)")
plot(x,y, type = 's', main = "(d)")
plot(x,y, type = "b", lty = 3, main = "y = x^2")
?legend
attach(mtcars)
head(mtcars, n = 2)
plot(mpg ~ disp, data = mtcars)
plot(hp ~ disp, data = mtcars)
x = rnorm(100)
y = 2+2*x + rnorm(100)
plot(x,y, main = "plot (x-y)")
x = seq(-2,2, length = 10)
y = x^2
par(mfrow = c(2,2))
plot(x,y, type = 'p', main = "(a)")
plot(x,y, type = 'b', main = "(b)")
plot(x,y, type = 'l', main = "(c)")
plot(x,y, type = 's', main = "(d)")
plot(x,y, type = "b", lty = 3, main = "y = x^2")
plot(x,y, type = "b", lty = 3, pch = 2, main = "y = x^2")
plot(x = 1:25,y = rep(0, 25), pch = 1:25)
plot(x,y, type = "b", lty = 3, pch = 2,
col = "blue", main = "y = x^2")
colors()[1:10]
plot(x,y, type = "b", xlab = "xx", ylab = "yy", main = "y = x^2")
plot(~mpg+disp+drat,data=mtcars,
main="Simple Scatterplot Matrix")
x = rnorm(100)
y = 2+2*x + rnorm(100)
plot(x,y, pch = 20, main = 'scatter plot')
abline(a = 1, b = 2, col = "red")
abline(v = 1, col = "blue")
abline(h = 1, col = "green")
plot(mpg~disp, data = cars, xlab = "displacement", ylab = "mile/gallon",
main = "scatter plot", pch = 20, col = 'darkblue')
plot(x = 1,y = 1, type = 'n', xlim = c(0,10), ylim = c(0,5),
xlab = 'time', ylab = '# of visiting')
x = 0:10
set.seed(1)
y = rpois(length(x), lambda = 1)
points(x, y, col = "blue", type = "s")
points(x, y, col = "red", type = "l")
plot(0,0, type = 'n', xlim = c(-2,2), ylim = c(-2,2))
x = c(-2,1,0,1,0)
y = c(0, -1, 2, -2,1)
lines(x,y)
plot(0,0, type = 'n', xlim = c(-2,2), ylim = c(-2,2))
x = c(-2, 1, NA, 1, 0)
y = c(0, -1, NA, -2, 1)
lines(x,y)
plot(0,0, type = 'n', xlim = c(-2,2), ylim = c(-2,2))
x = c(-2, 1, NA, 1, 0)
y = c(0, -1, NA, -2, 1)
lines(x,y, lty = 2)
z = sort(rnorm(100))
y1 = 2+ z + rnorm(100)
plot(z, y1, col = "blue", pch = 3)
points(z, y1/2, col = "red", pch = 19)
legend("topright", c("pch_3", "pch_19"), col = c("blue", "red"),
pch = c(3,19))
z = sort(rnorm(100))
y1 = 2+ z + rnorm(100)
plot(z, y1, col = "blue", pch = 3)
points(z, y1/2, col = "red", pch = 19)
legend("topright", c("pch_3", "pch_19"), col = c("blue", "red"),
pch = c(3,19))
set.seed(1)
x <- sort(rnorm(100))
y<- 3+x^2 + rnorm(100)
plot(x, y, pch = 20)
set.seed(1)
x <- sort(rnorm(100))
y<- 3+x^2 + rnorm(100)
plot(x, y, pch = 20)
par( mfrow = c(1,2))
plot(x, y, pch = 20)
abline( v = 1, col = 'black')
index.mat<- c(knnx.index(x, 1 , k = 10))
par( mfrow = c(1,2))
plot(x, y, pch = 20)
abline( v = 1, col = 'black')
index.mat<- c(knnx.index(x, 1 , k = 10))
set.seed(1)
x <- sort(rnorm(100))
y<- 3+x^2 + rnorm(100)
plot(x, y, pch = 20)
unlink('C:/Users/Jeon/Dropbox/class/2018 EDA/week_5/Rgraphics-2_cache', recursive = TRUE)
x = seq(-3,3, 100)
exp(0) - exp(0)*x +0.5*exp(0)x^2
exp(0) - exp(0)*x +0.5*exp(0)*x^2
x = seq(-3,3, 100)
exp(0) - exp(0)*x +0.5*exp(0)*x^2
x = seq(-3,3, length = 100)
exp(0) - exp(0)*x +0.5*exp(0)*x^2
y = exp(0) - exp(0)*x +0.5*exp(0)*x^2
y2 = exp(-x)
plot(x,y2, type='l')
lines(x,y2)
lines(x,y)
plot(x,y2, type='l')
lines(x,y)
plot(x,y2, type='l', col = 'red')
lines(x,y)
y2 = log( 1 + exp(-x))
plot(x,y2, type='l', col = 'red')
y2 = log( 1 + exp(-x))/log(2)
y2
y2 = log( 1 + exp(-x))/log(2)
plot(x,y2, type='l', col = 'red')
abline(v = 0)
abline(v = 0); abline(h=1,lty = 3)
y = 1 - 1/log(2)/2*x + 1/4/log(2)*x^2
plot(x,y2, type='l', col = 'red')
abline(v = 0); abline(h=1,lty = 3)
lines(x,y)
0.3
160*11
4*0.3
4*0.3*11
160*11
180*11
qlogis(0.852)
880/12
880/11
## description
## investigate the variance of the proposed estimator
rm(list = ls()); gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
require('glmnet')
library(igraph)
library(ggplot2)
library(dplyr)
source('./lib/sim.R')
################################################################################
max.k = 10
p = 10
kn <- 7  ## d
rn <- 3   ## n_s
df = 1    ## degree of freedom
counter = 1
sim.iter = 200    ## 전체 simulation 과정 반복 수
source('./lib/exe-2.R') # return the object, dmat
tn_vec = c(500,5000,50000)
cor.naive_list = list()
cor.r_list = list()
k_fold = 5
tn_i = 3
# simulation: number of obs.
tn = tn_vec[tn_i]  ## tn 정의 (전체 rank pair의 수.)
cat ('total n:' , tn , '\n')
cor.naive<- rep(0,sim.iter) ## BT를 이용한 kendall's tau 저장하는 벡터
gbt_trueMat <- matrix(NA,sim.iter,max.k)
gbt_truevec <- rep(NA, sim.iter)
bt_truevec <- rep(NA, sim.iter)
cor.cv <- matrix(0,sim.iter,max.k)
cor.cv.list = vector(mode = 'list', length = sim.iter)
ii = 1
for  (ii in 1:sim.iter)
{
cat(' ',ii,'-th iteration\n')
set.seed(ii+123) ## set seed
Qmat = sparse_gen_fun(dmat, kn, rn, tn)
gen_fit = gen_sim_fun(Gmat, Qmat)
cvec<-(0:(max.k-1))/tn  ## cvec : threshold cval
# cross validation
fit = cv.gbt_fun(gen_fit, cvec, k_fold, lambda.vec)
cv_mean_vec = colMeans(fit, na.rm = TRUE)
cor.cv.list[[ii]] = fit
cor.cv[ii,] =  cv_mean_vec
# cor.r
for (k in 1:length(cvec))
{
cval = cvec[k]
gbt_fit = gbt_fun(gen_fit, cval, lambda.vec)
gbt_trueMat[ii,k] = gbt_fit$cor
}
# cv selection
min_idx <-which.max(cv_mean_vec)
cval <-  cvec[min_idx]
gbt_fit = gbt_fun(gen_fit, cval, lambda.vec)
bt_fit = bt_fun(gen_fit, lambda.vec)
gbt_truevec[ii] = gbt_fit$cor
bt_truevec[ii] = bt_fit$cor
}
boxplot(gbt_truevec,bt_truevec)
save.image("sim_result_5-3.rdata")
