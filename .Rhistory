ls()
install.packages("FNN")
# Generate Train Data
set.seed(1)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
ab = 1
eval_n <- 100
# Generate Train Data
set.seed(1)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
ab = 1
k = 1
ii = 1
# Generate Train Data
set.seed(ii)
eval_n = 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
# Generate Test Data
x_test <- sort(rnorm(eval_n))
# Generate Test Data
x_test <- sort(rnorm(eval_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_n)
k = 10
k = 10
# k = 10
eval_point <- x_test
idx_mat <- knnx_index(x_train, eval_point, k)
idx_mat
library(FNN)
idx_mat <- knnx.index(x_train, eval_point, k)
idx_mat
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx.mat[i,]])
}
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx.mat[i,]])
}
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
yhat
mean((yhat - y_test)^2)
yhat
eval_point
eval_point <- x_test
eval_point
yhat
y_test
mean((yhat - y_test)^2)
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
# Generate Test Data
x_test <- sort(rnorm(eval_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn.sig[k] <- mean((yhat - y_test)^2)
}
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
# Generate Test Data
x_test <- sort(rnorm(eval_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
eval_test_n = 10000
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
eval_test_n = 10000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
library(FNN)
ii = 1
eval_n <- 100
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
eval_test_n = 100
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
library(FNN)
ii = 1
eval_n <- 1000
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- rep(0, 50)
eval_test_n = 1000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig)
plot(knn_sig, type = 'b', color = 'lightblue')
knn_sig <- seq(1,100,by = 5)
knn_sig <- seq(1,100,by = 5)
library(FNN)
ii = 1
eval_n <- 1000
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
knn_sig <- seq(1,100,by = 5)
eval_test_n = 1000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig, type = 'b', color = 'lightblue')
plot(knn_sig, type = 'b', col = 'lightblue')
knn_sig
seq(1,100, by = 5)
kvec <- seq(1,100, by = 5)
library(FNN)
ii = 1
eval_n <- 500
# Generate Train Data
set.seed(ii)
x_train <- sort(rnorm(eval_n))
y_train <- 3 + x_train ^ 2 + rnorm(eval_n)
yhat <- rep(0, eval_n)
kvec <- seq(1,100, by = 5)
error <- rep(0, length(kvec))
eval_test_n = 1000
# Generate Test Data
x_test <- sort(rnorm(eval_test_n))
y_test <- 3 + x_test ^ 2 + rnorm(eval_test_n)
for (k in 1:length(knn_sig))
{
eval_point <- x_test
idx_mat <- knnx.index(x_train, eval_point, k)
for (i in 1:eval_test_n)
{
yhat[i] <- mean(y_train[idx_mat[i,]])
}
knn_sig[k] <- mean((yhat - y_test)^2)
}
plot(knn_sig, type = 'b', col = 'lightblue')
plot(knn_sig, type = 'b', col = 'darkblue')
## description
## investigate the variance of the proposed estimator
rm(list = ls()); gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
require('glmnet')
library(igraph)
library(ggplot2)
library(dplyr)
source('./lib/sim.R')
################################################################################
max.k = 10
p = 10
kn <- 7  ## d
rn <- 3   ## n_s
df = 1    ## degree of freedom
counter = 1
sim.iter = 200    ## 전체 simulation 과정 반복 수
source('./lib/exe-2.R') # return the object, dmat
tn_vec = c(500,5000,50000)
cor.naive_list = list()
cor.r_list = list()
k_fold = 5
tn_i = 3
tn = tn_vec[tn_i]  ## tn 정의 (전체 rank pair의 수.)
cat ('total n:' , tn , '\n')
cor.naive<- rep(0,sim.iter) ## BT를 이용한 kendall's tau 저장하는 벡터
cor.r <- matrix(0,sim.iter,max.k) ## gBT를 이용한 kendall's tau 저장하는 벡터
ii = 1
k = 1
cval <- cvec[k]
# k-fold
k_num = 1
tmp_te = cv_mat[cv_mat[,"partition"] == k_num,-4]
tmp_tr = cv_mat[cv_mat[,"partition"] != k_num,-4]
cv_table <- cv_table_fun(tmp_tr)
Gmat.hat <- cv_table$G
Qmat <- cv_table$Q
## strat cv
Gmat.hat <- Gmat.hat/Qmat
Gmat.hat[!is.finite(Gmat.hat)] = 0
n = sum(Qmat)
Qpmat = Qmat/n*2
result <- gbt_step1_fun(Qpmat, Gmat.hat, p, cval)
# gbt_step2_fun
cv_table <- cv_table_fun(tmp_te)
gbt_fit<- gbt_step2_fun(result, p, lambda.vec, cv_table)
if (ii %% 10 == 0)  cat(' ',ii,'-th iteration\n')
set.seed(ii+123) ## set seed
### generating number of comparison using dmat
Qmat = sparse_gen_fun(dmat, kn, rn, tn)
cvec<-(0:(max.k-1))/tn  ## cvec : threshold cval
##############################
# function: gen_sim_fun, cv_mat_fun,
gen_fit = gen_sim_fun(Gmat, Qmat)
Gmat.hat_raw = gen_fit$G
Qmat_raw = gen_fit$Q
cv_mat = cv_mat_fun(gen_fit$G, gen_fit$Q)
k = 1
cval <- cvec[k]
# k-fold
k_num = 1
tmp_te = cv_mat[cv_mat[,"partition"] == k_num,-4]
tmp_tr = cv_mat[cv_mat[,"partition"] != k_num,-4]
cv_table <- cv_table_fun(tmp_tr)
Gmat.hat <- cv_table$G
Qmat <- cv_table$Q
## strat cv
Gmat.hat <- Gmat.hat/Qmat
Gmat.hat[!is.finite(Gmat.hat)] = 0
n = sum(Qmat)
Qpmat = Qmat/n*2
result <- gbt_step1_fun(Qpmat, Gmat.hat, p, cval)
# gbt_step2_fun
cv_table <- cv_table_fun(tmp_te)
gbt_fit<- gbt_step2_fun(result, p, lambda.vec, cv_table)
cat(cor.r,'\n')
gbt_fit
tn = tn_vec[tn_i]  ## tn 정의 (전체 rank pair의 수.)
cat ('total n:' , tn , '\n')
cor.naive<- rep(0,sim.iter) ## BT를 이용한 kendall's tau 저장하는 벡터
cor.r <- matrix(0,sim.iter,max.k) ## gBT를 이용한 kendall's tau 저장하는 벡터
ii = 1
cor.cv.list = vector(mode = 'list', length = sim.iter)
cor.cv.list.mat = matrix(NA, k_fold, length(cvec))
######### gBT model ###########
cval <- cvec[k]
# k-fold
k_num = 1
for (k_num in 1:k_fold)
max.k
colMean(cor.cv.list.mat)
colMeans(cor.cv.list.mat)
colMeans(cor.cv.list.mat, na.rm = TRUE)
## description
## investigate the variance of the proposed estimator
rm(list = ls()); gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
require('glmnet')
library(igraph)
library(ggplot2)
library(dplyr)
source('./lib/sim.R')
################################################################################
max.k = 10
p = 10
kn <- 7  ## d
rn <- 3   ## n_s
df = 1    ## degree of freedom
counter = 1
sim.iter = 5    ## 전체 simulation 과정 반복 수
source('./lib/exe-2.R') # return the object, dmat
tn_vec = c(500,5000,50000)
cor.naive_list = list()
cor.r_list = list()
k_fold = 5
tn_i = 3
# simulation: number of obs.
tn = tn_vec[tn_i]  ## tn 정의 (전체 rank pair의 수.)
cat ('total n:' , tn , '\n')
cor.naive<- rep(0,sim.iter) ## BT를 이용한 kendall's tau 저장하는 벡터
cor.r <- matrix(0,sim.iter,max.k)
cor.cv <- matrix(0,sim.iter,max.k)
cor.cv.list = vector(mode = 'list', length = sim.iter)
ii = 1
## description
## investigate the variance of the proposed estimator
rm(list = ls()); gc()
setwd("C:/Users/Jeon/Documents/GitHub/RankConsistency")
require('glmnet')
library(igraph)
library(ggplot2)
library(dplyr)
source('./lib/sim.R')
################################################################################
max.k = 10
p = 10
kn <- 7  ## d
rn <- 3   ## n_s
df = 1    ## degree of freedom
counter = 1
sim.iter = 5    ## 전체 simulation 과정 반복 수
source('./lib/exe-2.R') # return the object, dmat
tn_vec = c(500,5000,50000)
cor.naive_list = list()
cor.r_list = list()
k_fold = 5
tn_i = 3
# simulation: number of obs.
tn = tn_vec[tn_i]  ## tn 정의 (전체 rank pair의 수.)
cat ('total n:' , tn , '\n')
cor.naive<- rep(0,sim.iter) ## BT를 이용한 kendall's tau 저장하는 벡터
cor.r <- matrix(0,sim.iter,max.k)
cor.cv <- matrix(0,sim.iter,max.k)
cor.cv.list = vector(mode = 'list', length = sim.iter)
ii = 1
for  (ii in 1:sim.iter)
{
if (ii %% 10 == 0)  cat(' ',ii,'-th iteration\n')
set.seed(ii+123) ## set seed
### generating number of comparison using dmat
Qmat = sparse_gen_fun(dmat, kn, rn, tn)
cvec<-(0:(max.k-1))/tn  ## cvec : threshold cval
##############################
# function: gen_sim_fun, cv_mat_fun,
gen_fit = gen_sim_fun(Gmat, Qmat)
Gmat.hat_raw = gen_fit$G
Qmat_raw = gen_fit$Q
cv_mat = cv_mat_fun(gen_fit$G, gen_fit$Q)
k = 1
cor.cv.list.mat = matrix(NA, k_fold, length(cvec))
for (k in 1:length(cvec))
{
######### gBT model ###########
cval <- cvec[k]
# k-fold
k_num = 1
for (k_num in 1:k_fold)
{
tmp_te = cv_mat[cv_mat[,"partition"] == k_num,-4]
tmp_tr = cv_mat[cv_mat[,"partition"] != k_num,-4]
cv_table <- cv_table_fun(tmp_tr)
Gmat.hat <- cv_table$G
Qmat <- cv_table$Q
## strat cv
Gmat.hat <- Gmat.hat/Qmat
Gmat.hat[!is.finite(Gmat.hat)] = 0
n = sum(Qmat)
Qpmat = Qmat/n*2
result <- gbt_step1_fun(Qpmat, Gmat.hat, p, cval)
# gbt_step2_fun
cv_table <- cv_table_fun(tmp_te)
gbt_fit<- gbt_step2_fun(result, p, lambda.vec, cv_table)
cor.cv.list.mat[k_num, k] <- gbt_fit$cor
cat(cor.r,'\n')
}
}
cor.cv.list[[ii]] = cor.cv.list.mat
cor.cv[ii,] <- colMeans(cor.cv.list.mat, na.rm = TRUE)
}
gbt_fit$cor
cor.cv.list.mat
tn_i = 1
# simulation: number of obs.
tn = tn_vec[tn_i]  ## tn 정의 (전체 rank pair의 수.)
cat ('total n:' , tn , '\n')
cor.naive<- rep(0,sim.iter) ## BT를 이용한 kendall's tau 저장하는 벡터
cor.r <- matrix(0,sim.iter,max.k)
cor.cv <- matrix(0,sim.iter,max.k)
cor.cv.list = vector(mode = 'list', length = sim.iter)
ii = 1
gbt_fit
tmp = colMeans(cor.cv.list.mat, na.rm = TRUE)
tmp
cor.cv[ii,] <-
which,min(tmp)
tmp = colMeans(cor.cv.list.mat, na.rm = TRUE)
cor.cv[ii,] <-
which,min(tmp)
cor.cv[ii,] <-
which,min(tmp)
cor.cv[ii,] <-
which.min(tmp)
cor.cv[ii,] <-
which.min(tmp)
which.min(tmp)
vec[min_idx]
cvec[min_idx]
min_idx <-which.min(tmp)
cval <-  cvec[min_idx]
result
tmp_te
result <- gbt_step1_fun(Qpmat, Gmat.hat, p, cval)
gbt_fit<- gbt_step2_fun(result, p, lambda.vec)
gbt_fit
gbt_fit$cor
tn
